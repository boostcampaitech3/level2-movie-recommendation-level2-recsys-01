{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7CfnRw7U59C",
    "tags": []
   },
   "source": [
    "## 1. 초기 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQj6k1mSbxaz"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import bottleneck as bn\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import ndcg_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQ3W0udmbxa3",
    "outputId": "b5a12ce1-2e38-4bb2-a2c4-78ea6ab44af8"
   },
   "outputs": [],
   "source": [
    "## 각종 파라미터 세팅\n",
    "parser = argparse.ArgumentParser(description='PyTorch RecVAE')\n",
    "\n",
    "\n",
    "parser.add_argument('--data', type=str, default='../../data/train/',\n",
    "                    help='Movielens dataset location')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=5e-4,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--gamma', type=float, default=0.005)\n",
    "\n",
    "parser.add_argument('--batch_size', type=int, default=100,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=50,\n",
    "                    help='upper epoch limit')\n",
    "\n",
    "parser.add_argument('--n-enc_epochs', type=int, default=3)\n",
    "\n",
    "parser.add_argument('--n-dec_epochs', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='use CUDA')\n",
    "\n",
    "parser.add_argument('--save_dir', type=str, default='./',\n",
    "                    help='path to save the final model')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# Set the random seed manually for reproductibility.\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7o1fvXqFWE_G",
    "tags": []
   },
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgvNoy1Ybxa6"
   },
   "outputs": [],
   "source": [
    "#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n",
    "#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n",
    "#확인하기 위함입니다.\n",
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('user')\n",
    "    tr_list, te_list = list(), list()\n",
    "    \n",
    "    for _, group in data_grouped_by_user:\n",
    "        n_items_u = len(group)\n",
    "        \n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        \n",
    "        else:\n",
    "            print(f\"n_items_user is lower than 5, it is {n_items_u}\")\n",
    "            tr_list.append(group)\n",
    "    \n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "\n",
    "    return data_tr, data_te\n",
    "\n",
    "def numerize(df, user2id, item2id):\n",
    "    user = df['user'].apply(lambda x: user2id[x])\n",
    "    item = df['item'].apply(lambda x: item2id[x])\n",
    "    return pd.DataFrame(data={'user': user, 'item': item}, columns=['user', 'item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVFoRHrmVQsp",
    "outputId": "08f3516f-6475-4598-ffa0-21c570b1f185"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "DATA_DIR = args.data\n",
    "raw_data = pd.read_csv(os.path.join(args.data, 'train_ratings.csv'), header=0)\n",
    "print(\"원본 데이터\\n\", raw_data)\n",
    "\n",
    "user_review_count = raw_data[[\"user\"]].groupby(\"user\", as_index=False).size()\n",
    "item_review_count = raw_data[[\"item\"]].groupby(\"item\", as_index=False).size()\n",
    "print(\"유저별 리뷰수\\n\", user_review_count)\n",
    "print(\"아이템별 리뷰수\\n\",item_review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7T1dTsWUrffP",
    "outputId": "6979837a-b71e-4caa-f60e-e8aa5e8f0d55"
   },
   "outputs": [],
   "source": [
    "# Shuffle User Indices\n",
    "unique_user_id = raw_data[\"user\"].unique()\n",
    "unique_item_id = raw_data[\"item\"].unique()\n",
    "\n",
    "item2id = dict((item_id, i) for (i, item_id) in enumerate(unique_item_id))\n",
    "user2id = dict((user_id, i) for (i, user_id) in enumerate(unique_user_id))\n",
    "\n",
    "\n",
    "# print(\"(BEFORE) unique_user_id:\", unique_user_id)\n",
    "idx_perm = np.random.permutation(unique_user_id.size)\n",
    "unique_user_id = unique_user_id[idx_perm]\n",
    "# print(\"(AFTER) unique_user_id:\",unique_user_id)\n",
    "\n",
    "num_users = unique_user_id.size #31360\n",
    "num_items = unique_item_id.size #6807\n",
    "print(f\"전체 유저 수, 전체 영화 수: {num_users}, {num_items}\")\n",
    "\n",
    "# Split Train/Validation/Test User Indices\n",
    "valid_users = unique_user_id[-int(num_users * 0.2):]\n",
    "train_users = unique_user_id[:int(num_users * 0.8)]\n",
    "\n",
    "#주의: 데이터의 수가 아닌 사용자의 수입니다!\n",
    "print(\"훈련 데이터에 사용될 사용자 수:\", len(train_users))\n",
    "print(\"검증 데이터에 사용될 사용자 수:\", len(valid_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yBsRCRqtPz6",
    "outputId": "f9118ab3-aa55-44dc-aaaa-249704e5156e"
   },
   "outputs": [],
   "source": [
    "##훈련 데이터에 해당하는 아이템들\n",
    "#Train에는 전체 데이터를 사용합니다.\n",
    "train_data = raw_data.loc[raw_data['user'].isin(train_users)]\n",
    "train_data = numerize(train_data, user2id, item2id)\n",
    "\n",
    "#Validation으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다.\n",
    "valid_data = raw_data.loc[raw_data['user'].isin(valid_users)]\n",
    "valid_data_tr, valid_data_te = split_train_test_proportion(valid_data)\n",
    "valid_data_tr = numerize(valid_data_tr, user2id, item2id)\n",
    "valid_data_te = numerize(valid_data_te, user2id, item2id)\n",
    "\n",
    "total_data = numerize(raw_data, user2id, item2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yBsRCRqtPz6",
    "outputId": "f9118ab3-aa55-44dc-aaaa-249704e5156e"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data_tr, valid_data_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMiq9leyWWL1",
    "tags": []
   },
   "source": [
    "## 3. Dataset 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEDataset(Dataset):\n",
    "    def __init__(self, X, Y=None, num_users=31360, num_items=6807):\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.X = self._data_to_tensor(X)\n",
    "        if Y is not None:\n",
    "            self.Y = self._data_to_tensor(Y)\n",
    "        else:\n",
    "            self.Y = self.X\n",
    "        \n",
    "    \n",
    "    def _data_to_tensor(self, data, user='user', item='item'):\n",
    "        matrix = np.zeros((self.num_users, self.num_items))\n",
    "        matrix[data[user].values, data[item].values] = 1.0\n",
    "        matrix = matrix[np.any(matrix, axis=1)]\n",
    "        return torch.FloatTensor(matrix)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.size()[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FHhwKqXWaUZ",
    "tags": []
   },
   "source": [
    "## 4. 모델정의\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecVAE\n",
    "\n",
    "def swish(x):\n",
    "    return x.mul(torch.sigmoid(x))\n",
    "\n",
    "def log_norm_pdf(x, mu, logvar):\n",
    "    return -0.5*(logvar + np.log(2 * np.pi) + (x - mu).pow(2) / logvar.exp())\n",
    "\n",
    "\n",
    "class CompositePrior(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, mixture_weights=[3/20, 3/4, 1/10]):\n",
    "        super(CompositePrior, self).__init__()\n",
    "        \n",
    "        self.mixture_weights = mixture_weights\n",
    "        \n",
    "        self.mu_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.mu_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_prior.data.fill_(0)\n",
    "        \n",
    "        self.logvar_uniform_prior = nn.Parameter(torch.Tensor(1, latent_dim), requires_grad=False)\n",
    "        self.logvar_uniform_prior.data.fill_(10)\n",
    "        \n",
    "        self.encoder_old = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.encoder_old.requires_grad_(False)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        post_mu, post_logvar = self.encoder_old(x, 0)\n",
    "        \n",
    "        stnd_prior = log_norm_pdf(z, self.mu_prior, self.logvar_prior)\n",
    "        post_prior = log_norm_pdf(z, post_mu, post_logvar)\n",
    "        unif_prior = log_norm_pdf(z, self.mu_prior, self.logvar_uniform_prior)\n",
    "        \n",
    "        gaussians = [stnd_prior, post_prior, unif_prior]\n",
    "        gaussians = [g.add(np.log(w)) for g, w in zip(gaussians, self.mixture_weights)]\n",
    "        \n",
    "        density_per_gaussian = torch.stack(gaussians, dim=-1)\n",
    "                \n",
    "        return torch.logsumexp(density_per_gaussian, dim=-1)\n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim, eps=1e-1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln3 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln4 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.ln5 = nn.LayerNorm(hidden_dim, eps=eps)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x, dropout_rate):\n",
    "        norm = x.pow(2).sum(dim=-1).sqrt()\n",
    "        x = x / norm[:, None]\n",
    "        # x[x != x] = 0\n",
    "    \n",
    "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "        \n",
    "        h1 = self.ln1(swish(self.fc1(x)))\n",
    "        h2 = self.ln2(swish(self.fc2(h1) + h1))\n",
    "        h3 = self.ln3(swish(self.fc3(h2) + h1 + h2))\n",
    "        h4 = self.ln4(swish(self.fc4(h3) + h1 + h2 + h3))\n",
    "        h5 = self.ln5(swish(self.fc5(h4) + h1 + h2 + h3 + h4))\n",
    "        return self.fc_mu(h5), self.fc_logvar(h5)\n",
    "    \n",
    "\n",
    "class RecVAE(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, input_dim):\n",
    "        super(RecVAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(hidden_dim, latent_dim, input_dim)\n",
    "        self.prior = CompositePrior(hidden_dim, latent_dim, input_dim)\n",
    "        self.decoder = nn.Linear(latent_dim, input_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, user_ratings, beta=None, gamma=1, dropout_rate=0.5, calculate_loss=True):\n",
    "        mu, logvar = self.encoder(user_ratings, dropout_rate=dropout_rate)    \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_pred = self.decoder(z)       \n",
    "        \n",
    "        if gamma:\n",
    "            norm = user_ratings.sum(dim=-1)\n",
    "            kl_weight = gamma * norm\n",
    "        elif beta:\n",
    "            kl_weight = beta\n",
    "\n",
    "        mll = (F.log_softmax(x_pred, dim=-1) * user_ratings).sum(dim=-1).mean()\n",
    "        kld = (log_norm_pdf(z, mu, logvar) - self.prior(user_ratings, z)).sum(dim=-1).mul(kl_weight).mean()\n",
    "        negative_elbo = -(mll - kld)\n",
    "        \n",
    "        return negative_elbo, x_pred\n",
    "\n",
    "\n",
    "    def update_prior(self):\n",
    "        self.prior.encoder_old.load_state_dict(deepcopy(self.encoder.state_dict()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metric (recall@k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k_batch(X_pred, heldout_batch, k=10):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0)\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    return tmp / np.minimum(k, X_true_binary.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78zFFNzgbxa_"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "train_dataloader = DataLoader(VAEDataset(train_data),\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=multiprocessing.cpu_count() // 2)\n",
    "\n",
    "valid_dataloader = DataLoader(VAEDataset(valid_data_tr, valid_data_te),\n",
    "                              batch_size=len(valid_users), \n",
    "                              shuffle=False,\n",
    "                              num_workers=multiprocessing.cpu_count() // 2)\n",
    "\n",
    "total_dataloader = DataLoader(VAEDataset(total_data),\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=multiprocessing.cpu_count() // 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build Model & Run Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoUFwndCvvtp",
    "outputId": "5aef1fa2-a616-4494-d48a-6c8997e3190c"
   },
   "outputs": [],
   "source": [
    "# ###############################################################################\n",
    "# # Build the model\n",
    "# ###############################################################################\n",
    "args.epochs = 200\n",
    "args.lr = 5e-4\n",
    "args.gamma = 0.005\n",
    "args.batch_size = 500\n",
    "\n",
    "latent_dim, hidden_dim, input_dim = [200, 600, num_items]\n",
    "model = RecVAE(hidden_dim, latent_dim, input_dim).to(device)\n",
    "\n",
    "enc_optimizer = optim.Adam(model.encoder.parameters(), lr=args.lr)\n",
    "dec_optimizer = optim.Adam(model.decoder.parameters(), lr=args.lr)\n",
    "\n",
    "model_params = {'hidden_dims': (latent_dim, hidden_dim, input_dim),\n",
    "                \"optimizer\": enc_optimizer,\n",
    "                \"enc_epoch / dec_epoch\": 3,\n",
    "                \"gamma\": args.gamma\n",
    "               }\n",
    "\n",
    "args.save_dir = f'./output/epoch{args.epochs}_adam{args.lr}_gamma{args.gamma}_batch{args.batch_size}_hidden{(latent_dim, hidden_dim, input_dim)}'\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "model_params, device, args.save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WoUFwndCvvtp",
    "outputId": "5aef1fa2-a616-4494-d48a-6c8997e3190c"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Training code\n",
    "###############################################################################\n",
    "best_r10 = -np.inf\n",
    "best_epoch = 0\n",
    "train_loss_list = list()\n",
    "valid_loss_list = list()\n",
    "valid_r10_list = list()\n",
    "valid_r20_list = list()\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # train\n",
    "    for x, y in train_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # encoder\n",
    "        for i in range(args.n_enc_epochs):\n",
    "            enc_optimizer.zero_grad()\n",
    "            loss, _ = model(x, gamma=args.gamma, dropout_rate=0.5)\n",
    "            loss.backward()\n",
    "            enc_optimizer.step()\n",
    "        \n",
    "        model.update_prior()\n",
    "        \n",
    "        #decoder\n",
    "        for i in range(args.n_dec_epochs):\n",
    "            dec_optimizer.zero_grad()\n",
    "            loss, _ = model(x, gamma=args.gamma, dropout_rate=0.0)\n",
    "            loss.backward()\n",
    "            dec_optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    train_loss_list.append(train_loss / len(train_dataloader))\n",
    "    \n",
    "    model.eval()\n",
    "    for x, y in valid_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        val_loss, pred = model(x, calculate_loss=False)\n",
    "        \n",
    "        # Exclude examples from training set\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        pred[x.detach().cpu().numpy().nonzero()] = -np.inf\n",
    "\n",
    "        r10 = recall_at_k_batch(pred, y.detach().cpu().numpy(), 10).mean()\n",
    "        r20 = recall_at_k_batch(pred, y.detach().cpu().numpy(), 20).mean()\n",
    "    \n",
    "    valid_loss_list.append(val_loss.item())\n",
    "    valid_r10_list.append(r10)\n",
    "    valid_r20_list.append(r20)\n",
    "        \n",
    "    print(f\"| end of epoch {epoch} | time: {time.time() - epoch_start_time:4.2f}s \"\n",
    "          f\"| valid loss {val_loss:4.2f} \"\n",
    "          f\"| r10 {r10:6.4f} \"\n",
    "          f\"| r20 {r20:6.4f}\")\n",
    "\n",
    "\n",
    "    # Save the model if the n100 is the best we've seen so far.\n",
    "    if r10 > best_r10:\n",
    "        with open(os.path.join(args.save_dir, \"model.pt\"), 'wb') as f:\n",
    "            torch.save(model, f)\n",
    "        best_r10 = r10\n",
    "        best_epoch = epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8. Loss 변화 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(1, args.epochs + 1), train_loss_list, label=\"train_loss\")\n",
    "plt.plot(range(1, len(valid_loss_list) + 1), valid_loss_list, label=\"valid_loss\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(args.save_dir, \"loss.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(valid_r10_list) + 1), valid_r10_list, label=\"r10\")\n",
    "plt.plot(range(1, len(valid_r20_list) + 1), valid_r20_list, label=\"r20\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(args.save_dir, f\"recall_best{best_epoch}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. output file 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_data\n",
    "best_model = torch.load(os.path.join(args.save_dir, 'model.pt')).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_output = list()\n",
    "best_model.eval()\n",
    "\n",
    "for x, _ in tqdm(total_dataloader):\n",
    "    x = x.to(device)\n",
    "    \n",
    "    _, pred_out = best_model(x, calculate_loss=False)\n",
    "    pred_out = pred_out.detach().cpu().numpy()\n",
    "    pred_out[x.detach().cpu().numpy().nonzero()] = -np.inf\n",
    "    \n",
    "    idxs = bn.argpartition(-pred_out, 10, axis=1)\n",
    "    item_output.extend(idxs[: ,:10].reshape(-1, ))\n",
    "len(item_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_items = np.array(sorted(item2id.items(), key=lambda x: x[1]))[item_output, 0]\n",
    "sub_items[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"../../movies_info.csv\")\n",
    "movies_df.loc[movies_df.item.isin(sub_items[:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../../data/eval/sample_submission.csv\")\n",
    "submission[\"item\"] = sub_items\n",
    "submission.to_csv(os.path.join(args.save_dir,\n",
    "                               f\"./RecVAE_epoch{args.epochs}_adam{args.lr}_hidden{model_params['hidden_dims']}.csv\"),\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opt. output.csv with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with score\n",
    "best_model = torch.load(os.path.join('./output/epoch500_adam0.0005_batch500_hidden(200, 600, 6807)/', 'with_total_dataset_model.pt'))\n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataloader = DataLoader(VAEDataset(total_data),\n",
    "                                  batch_size=3000,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=multiprocessing.cpu_count() // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "K = 50\n",
    "scaler = MinMaxScaler()\n",
    "item_output = list()\n",
    "best_model.eval()\n",
    "\n",
    "for x, _ in tqdm(inference_dataloader):\n",
    "    x = x.to(device)\n",
    "    \n",
    "    _, pred_out = best_model(x, calculate_loss=False)\n",
    "    pred_out = pred_out.detach().cpu().numpy()\n",
    "    pred_out[x.detach().cpu().numpy().nonzero()] = -np.inf\n",
    "\n",
    "    for pred in pred_out:\n",
    "        pred_item_ids = np.where(pred != -np.inf)[0]\n",
    "        pred = scaler.fit_transform(pred[pred_item_ids].reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "        idx_score = np.vstack((pred_item_ids, pred)).T\n",
    "        idx_score = idx_score[idx_score[:, 1].argsort()[::-1]][:K]\n",
    "        \n",
    "        item_output.extend(idx_score.astype(float))\n",
    "\n",
    "len(item_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "sub_users = np.sort(unique_user_id).repeat(K)\n",
    "item_output = np.array(item_output)\n",
    "sub_items = np.array(sorted(item2id.items(), key=lambda x: x[1]))[item_output[:, 0].astype(int), 0]\n",
    "sub_scores = item_output[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"../../movies_info.csv\")\n",
    "sub_items[:K]\n",
    "movies_df.loc[movies_df.item.isin(sub_items[:K])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "submission = pd.DataFrame(0, index=np.arange(sub_users.shape[0]), columns=[\"user\", \"item\", \"score\"])\n",
    "\n",
    "submission.user = sub_users\n",
    "submission.item = sub_items\n",
    "submission.score = sub_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "submission.to_csv(os.path.join('./output/epoch500_adam0.0005_batch500_hidden(200, 600, 6807)/',\n",
    "                               f\"./RecVAE_score{K}_epoch500_adam0.0005_hidden(200, 600, 6807).csv\"),\n",
    "                  index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mission2_Multi-VAE-정답",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
